Loading CNN models...
Top-3 Models: GB Base, MLP Base, GB Engineered
Method: Logistic Regression-based Stacked Ensemble Model

Fold 1/5
--------------------------------------------------
Getting CNN predictions on training set...
Getting CNN predictions on validation set...

Training Model 1/3: Gradient Boosting (Base)
Training Model 2/3: MLP (Base)
Training Model 3/3: Gradient Boosting (Engineered)
Fold 1: OOF predictions collected

Fold 2/5
--------------------------------------------------
Getting CNN predictions on training set...
Getting CNN predictions on validation set...

Training Model 1/3: Gradient Boosting (Base)
Training Model 2/3: MLP (Base)
Training Model 3/3: Gradient Boosting (Engineered)
Fold 2: OOF predictions collected

Fold 3/5
--------------------------------------------------
Getting CNN predictions on training set...
Getting CNN predictions on validation set...

Training Model 1/3: Gradient Boosting (Base)
Training Model 2/3: MLP (Base)
Training Model 3/3: Gradient Boosting (Engineered)
Fold 3: OOF predictions collected

Fold 4/5
--------------------------------------------------
Getting CNN predictions on training set...
Getting CNN predictions on validation set...

Training Model 1/3: Gradient Boosting (Base)
Training Model 2/3: MLP (Base)
Training Model 3/3: Gradient Boosting (Engineered)
Fold 4: OOF predictions collected

Fold 5/5
--------------------------------------------------
Getting CNN predictions on training set...
Getting CNN predictions on validation set...

Training Model 1/3: Gradient Boosting (Base)
Training Model 2/3: MLP (Base)
Training Model 3/3: Gradient Boosting (Engineered)
Fold 5: OOF predictions collected

Running nested cross-validation for meta-learner...
Outer Fold 1/5
Outer Fold 2/5
Outer Fold 3/5
Outer Fold 4/5
Outer Fold 5/5

Out-of-Fold Results (Nested CV):
--------------------------------------------------
AUC: 0.9276
F1 Score (0.5 threshold): 0.7640
Precision (0.5 threshold): 0.7253
Recall (0.5 threshold): 0.8355
Accuracy (0.5 threshold): 0.8983

Training final meta-learner on full OOF...
Fitting 5 folds for each of 12 candidates, totalling 60 fits
Best hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}
Best CV AUC: 0.9288
Optimal threshold (from final meta-learner OOF): 0.260

Final Meta-Learner OOF Metrics (optimized threshold):
AUC: 0.9281
F1 Score: 0.7813
Precision: 0.7702
Recall: 0.7938
Accuracy: 0.9215

Training final base models on full train+val set...

Test AUC: 0.9321
Test F1: 0.7696
Test Precision: 0.7522
Test Recall: 0.7910
Test Accuracy: 0.9147

